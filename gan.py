# -*- coding: utf-8 -*-
"""GAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18ghc_IXCz-N_V-2ig9FQWULcRh8W37PO
"""

import glob
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from keras.models import Sequential, Model
from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Activation
from keras.layers import BatchNormalization, ZeroPadding2D
from keras.layers.convolutional import Conv2D, UpSampling2D
from keras.layers.advanced_activations import LeakyReLU
from keras.optimizers import Adam

class DCGAN:
    def __init__(self):
        self.pikachuData = []
        #descriminator
        self.discriminator = self.buildDiscriminator()
        self.discriminator.compile(loss="binary_crossentropy", optimizer=Adam(lr=0.0002, beta_1=0.5),metrics=["accuracy"])
        #generator
        self.generator = self.buildGenerator()
        #combined model
        z = Input(shape=(100,))
        img = self.generator(z)
        self.discriminator.trainable = False
        valid = self.discriminator(img)
        self.combined = Model(z, valid)
        self.combined.compile(loss="binary_crossentropy", optimizer = Adam(lr=0.0002, beta_1=0.5))

    def buildDiscriminator(self):
        model = Sequential()
        #point: Use strides instead of pooling
        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=(128,128,3), padding="same"))
        model.add(LeakyReLU(alpha=0.2))
        model.add(Dropout(0.25))
        model.add(Conv2D(64, kernel_size=3, strides=2, padding="same"))
        #What's is zeropadding??????????????????????????????
        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))
        model.add(LeakyReLU(alpha=0.2))
        model.add(Dropout(0.25))
        model.add(BatchNormalization(momentum=0.8))
        model.add(Conv2D(128, kernel_size=3, strides=2, padding="same"))
        model.add(LeakyReLU(alpha=0.2))
        model.add(Dropout(0.25))
        #model.add(BatchNormalization(momentum=0.8))
        #model.add(Conv2D(128, kernel_size=3, strides=1, padding="same"))
        #model.add(LeakyReLU(alpha=0.2))
        #model.add(Dropout(0.25))

        model.add(Flatten())
        model.add(Dense(1, activation='sigmoid'))

        model.summary()

        img = Input(shape=(128,128,3))
        validity = model(img)
        return Model(img, validity)

    def buildGenerator(self):
        model = Sequential()

        model.add(Dense(128 * 32 * 32, activation="relu", input_shape=(100,)))
        model.add(Reshape((32, 32, 128)))
        model.add(BatchNormalization(momentum=0.8))
        model.add(UpSampling2D())
        model.add(Conv2D(128, kernel_size=3, padding="same"))
        model.add(Activation("relu"))
        model.add(BatchNormalization(momentum=0.8))
        model.add(UpSampling2D())
        model.add(Conv2D(64, kernel_size=3, padding="same"))
        model.add(Activation("relu"))
        model.add(BatchNormalization(momentum=0.8))
        model.add(Conv2D(3, kernel_size=3, padding="same"))
        model.add(Activation("tanh"))

        model.summary()

        noise = Input(shape=(100,))
        img = model(noise)
        return Model(noise, img)

    def loadImage(self):
        imagePaths = glob.glob(directoryPath + "/*.jpg")
        print("number of pics:%d" % len(imagePaths))
        i = 1
        for imagePath in imagePaths:
          print(imagePath)
          image = Image.open(imagePath)
          image = image.resize((128,128))
          image = np.array(image)
          image = image.astype("float32")
          image = image / 255
          self.pikachuData.append(image)

        self.pikachuData = np.array(self.pikachuData)

    def saveImage(self, epoch):
        noise = np.random.uniform(-1, 1, (25, 100))
        fakePikachu = self.generator.predict(noise)
        fakePikachu = 0.5 * fakePikachu + 0.5
        fig, axs = plt.subplots(5, 5)
        counter = 0
        for i in range(5):
            for j in range(5):
                axs[i,j].imshow(fakePikachu[counter,:,:,:])
                axs[i,j].axis('off')
                counter = counter + 1
        fig.savefig("/content/drive/My Drive/DNN/Face/Face_result/epoch%d.png" % epoch)

        plt.close()

    def main(self):
        #load_image
        self.loadImage()
        #mini batch size
        halfBatch = int(batchSize/2)
        #label for training discriminator
        realLabelForDis = np.ones((halfBatch, 1))
        fakeLabelForDis = np.zeros((halfBatch, 1))
        #label for training generator
        realLabelForGen = np.ones((batchSize, 1))

        for epoch in range(epochs):
            #-------------Discriminator-------------------------
            #real pikachu
            pikachuIndex = np.random.randint(0, self.pikachuData.shape[0], halfBatch)
            realPikachu = self.pikachuData[pikachuIndex]
            #fake pikachu
            noise = np.random.uniform(-1, 1, (halfBatch, 100))
            fakePikachu = self.generator.predict(noise)
            #train discriminator
            disLossReal = self.discriminator.train_on_batch(realPikachu, realLabelForDis)
            disLossFake = self.discriminator.train_on_batch(fakePikachu, fakeLabelForDis)
            disLoss = np.add(disLossReal, disLossFake) * 0.5

            #-------------Generator-------------------------
            noise = np.random.uniform(-1, 1, (batchSize, 100))
            genLoss = self.combined.train_on_batch(noise, realLabelForGen)

            #output information
            print("[epoch]: %d, [Dis] Loss: %f, Acc: %.2f%%, [Gen] Loss: %f" % (epoch, disLoss[0], 100*disLoss[1],genLoss))

            #-------------Save image------------------------
            if epoch % saveInterval == 0:
                print("save image...")
                self.saveImage(epoch)

#---------premise------------------------------------
directoryPath = "/content/drive/My Drive/DNN/Face/Face_data"
epochs = 50000
batchSize = 128
saveInterval = 1000

#--------instance---------------------------------------
dcgan = DCGAN()
dcgan.main()
print("finish")
